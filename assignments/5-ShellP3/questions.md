1. Your shell forks multiple child processes when executing piped commands. How does your implementation ensure that all child processes complete before the shell continues accepting user input? What would happen if you forgot to call waitpid() on all child processes?

My implementation ensures that all child processes complete before the shell continues accepting user input by using waitpid() in a loop. When executing a piped command, the shell forks multiple child processes, each responsible for a stage in the pipeline. After forking all processes, the parent shell iterates through their process IDs and calls waitpid() to wait for each child to terminate before displaying the next command prompt. If waitpid() were not used, child processes would become zombie processes, remaining in the system’s process table until explicitly collected by the parent. Over time, these zombie processes could accumulate and exhaust system resources, potentially leading to performance issues. Additionally, without proper synchronization, the shell might begin prompting for new commands while some child processes are still running, causing unpredictable behavior and output interleaving.

2. The dup2() function is used to redirect input and output file descriptors. Explain why it is necessary to close unused pipe ends after calling dup2(). What could go wrong if you leave pipes open?

The dup2() function is used to redirect input and output file descriptors, making it essential to close unused pipe ends afterward. If pipes are left open unnecessarily, several problems can occur. One major issue is deadlocks—if a process expects input from a pipe but the write end remains open, it may never receive an end-of-file (EOF) signal and could hang indefinitely. Additionally, open file descriptors consume system resources, and excessive open pipes could lead to file descriptor exhaustion, preventing new processes from creating pipes. Another risk is unintended data corruption, as leaving both ends of a pipe open could lead to data being written to or read from the wrong place. Closing unused pipe ends ensures that each process only interacts with the necessary parts of the pipeline and prevents resource leaks, improving both efficiency and stability.

3. Your shell recognizes built-in commands (cd, exit, dragon). Unlike external commands, built-in commands do not require execvp(). Why is cd implemented as a built-in rather than an external command? What challenges would arise if cd were implemented as an external process?

The cd command is implemented as a built-in because it modifies the current working directory of the shell process itself. If cd were implemented as an external command, it would execute in a child process created via fork(), but any changes it made to the working directory would not persist after the child process terminates. Since the parent shell would remain in the same directory, the command would be effectively useless. The only way to change the working directory of the parent process is by calling chdir() directly within the shell, which is why cd must be handled as a built-in command. If implemented as an external process, it would require an impractical workaround to communicate the new directory back to the parent shell, making execution cumbersome and inefficient.

4. Currently, your shell supports a fixed number of piped commands (CMD_MAX). How would you modify your implementation to allow an arbitrary number of piped commands while still handling memory allocation efficiently? What trade-offs would you need to consider?

Currently, the shell supports a fixed number of piped commands using a predefined array size (CMD_MAX). To allow an arbitrary number of piped commands while managing memory efficiently, a dynamic memory allocation approach can be used. Instead of a static array, malloc() can allocate memory for command structures, and if more commands are parsed, realloc() can expand the allocation as needed. This ensures that memory is used efficiently and prevents unnecessary restrictions on the number of piped commands a user can execute. However, this approach introduces trade-offs. Dynamically resizing structures incurs performance overhead compared to a fixed-size array, and proper memory management is necessary to prevent leaks. Additionally, bounds checking is crucial to avoid buffer overflows or running out of memory. A balanced solution would be to start with a reasonable default allocation and dynamically expand only when necessary, optimizing both flexibility and efficiency.
